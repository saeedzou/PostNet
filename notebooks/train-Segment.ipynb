{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/saeedzou/PostNet.git\n",
    "!pip -q install pyro-ppl\n",
    "\n",
    "import os\n",
    "print(\"Current Working Directory \" , os.getcwd())\n",
    "import sys\n",
    "sys.path.append(\"PostNet\") # Add directory containing src/data to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from src.posterior_networks.run import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "seed_dataset=123\n",
    "directory_dataset='PostNet/data'\n",
    "dataset_name='segment_scale_sky_missing'\n",
    "ood_dataset_names=['segment_scale_sky_only']\n",
    "unscaled_ood=False\n",
    "split=[.6, .8]\n",
    "transform_min=0.\n",
    "transform_max=1.\n",
    "\n",
    "# Architecture parameters\n",
    "seed_model=123\n",
    "directory_model='PostNet/saved_models'\n",
    "architecture='linear'\n",
    "input_dims=[18]\n",
    "output_dim=6\n",
    "hidden_dims=[64, 64, 64]\n",
    "kernel_dim=None\n",
    "latent_dim=6\n",
    "no_density=False\n",
    "density_type='normal_mixture'\n",
    "n_density=6\n",
    "k_lipschitz=None\n",
    "budget_function='id'\n",
    "\n",
    "# Training parameters\n",
    "directory_results='PostNet/saved_results'\n",
    "max_epochs=200\n",
    "patience=10\n",
    "frequency=2\n",
    "batch_size=64\n",
    "lr=1e-3\n",
    "loss='UCE'\n",
    "training_mode='joint'\n",
    "regr=1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/staff-hdd/charpent/anaconda3/envs/posterior-network/lib/python3.6/site-packages/torch/autograd/anomaly_mode.py:70: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  warnings.warn('Anomaly Detection has been enabled. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> Val loss 2.103 | Val Acc.: 0.167\n",
      "Model saved\n",
      "Epoch 2 -> Val loss 2.013 | Val Acc.: 0.285\n",
      "Model saved\n",
      "Epoch 4 -> Val loss 1.523 | Val Acc.: 0.831\n",
      "Model saved\n",
      "Epoch 6 -> Val loss 1.227 | Val Acc.: 0.876\n",
      "Model saved\n",
      "Epoch 8 -> Val loss 1.193 | Val Acc.: 0.854\n",
      "Model saved\n",
      "Epoch 10 -> Val loss 1.034 | Val Acc.: 0.866\n",
      "Model saved\n",
      "Epoch 12 -> Val loss 0.826 | Val Acc.: 0.909\n",
      "Model saved\n",
      "Epoch 14 -> Val loss 0.77 | Val Acc.: 0.899\n",
      "Model saved\n",
      "Epoch 16 -> Val loss 0.626 | Val Acc.: 0.914\n",
      "Model saved\n",
      "Epoch 18 -> Val loss 0.618 | Val Acc.: 0.927\n",
      "Model saved\n",
      "Epoch 20 -> Val loss 0.51 | Val Acc.: 0.939\n",
      "Model saved\n",
      "Epoch 22 -> Val loss 0.611 | Val Acc.: 0.876\n",
      "Epoch 24 -> Val loss 0.476 | Val Acc.: 0.917\n",
      "Model saved\n",
      "Epoch 26 -> Val loss 0.402 | Val Acc.: 0.947\n",
      "Model saved\n",
      "Epoch 28 -> Val loss 0.389 | Val Acc.: 0.924\n",
      "Model saved\n",
      "Epoch 30 -> Val loss 0.34 | Val Acc.: 0.932\n",
      "Model saved\n",
      "Epoch 32 -> Val loss 0.354 | Val Acc.: 0.919\n",
      "Epoch 34 -> Val loss 0.394 | Val Acc.: 0.904\n",
      "Epoch 36 -> Val loss 0.251 | Val Acc.: 0.962\n",
      "Model saved\n",
      "Epoch 38 -> Val loss 0.26 | Val Acc.: 0.955\n",
      "Epoch 40 -> Val loss 0.241 | Val Acc.: 0.952\n",
      "Model saved\n",
      "Epoch 42 -> Val loss 0.368 | Val Acc.: 0.909\n",
      "Epoch 44 -> Val loss 0.357 | Val Acc.: 0.917\n",
      "Epoch 46 -> Val loss 0.272 | Val Acc.: 0.924\n",
      "Epoch 48 -> Val loss 0.282 | Val Acc.: 0.952\n",
      "Epoch 50 -> Val loss 0.33 | Val Acc.: 0.914\n",
      "Epoch 52 -> Val loss 0.235 | Val Acc.: 0.942\n",
      "Model saved\n",
      "Epoch 54 -> Val loss 0.221 | Val Acc.: 0.939\n",
      "Model saved\n",
      "Epoch 56 -> Val loss 0.257 | Val Acc.: 0.952\n",
      "Epoch 58 -> Val loss 0.219 | Val Acc.: 0.939\n",
      "Model saved\n",
      "Epoch 60 -> Val loss 0.177 | Val Acc.: 0.962\n",
      "Model saved\n",
      "Epoch 62 -> Val loss 0.194 | Val Acc.: 0.949\n",
      "Epoch 64 -> Val loss 0.196 | Val Acc.: 0.952\n",
      "Epoch 66 -> Val loss 0.283 | Val Acc.: 0.955\n",
      "Epoch 68 -> Val loss 0.31 | Val Acc.: 0.914\n",
      "Epoch 70 -> Val loss 0.301 | Val Acc.: 0.907\n",
      "Epoch 72 -> Val loss 0.205 | Val Acc.: 0.942\n",
      "Epoch 74 -> Val loss 0.252 | Val Acc.: 0.934\n",
      "Epoch 76 -> Val loss 0.166 | Val Acc.: 0.962\n",
      "Model saved\n",
      "Epoch 78 -> Val loss 0.216 | Val Acc.: 0.942\n",
      "Epoch 80 -> Val loss 0.204 | Val Acc.: 0.947\n",
      "Epoch 82 -> Val loss 0.187 | Val Acc.: 0.947\n",
      "Epoch 84 -> Val loss 0.211 | Val Acc.: 0.937\n",
      "Epoch 86 -> Val loss 0.244 | Val Acc.: 0.952\n",
      "Epoch 88 -> Val loss 0.192 | Val Acc.: 0.949\n",
      "Epoch 90 -> Val loss 0.297 | Val Acc.: 0.934\n",
      "Epoch 92 -> Val loss 0.22 | Val Acc.: 0.944\n",
      "Epoch 94 -> Val loss 0.272 | Val Acc.: 0.914\n",
      "Early Stopping.\n"
     ]
    }
   ],
   "source": [
    "results_metrics = run(# Dataset parameters\n",
    "                        seed_dataset,  # Seed to shuffle dataset. int\n",
    "                        directory_dataset,  # Path to dataset. string\n",
    "                        dataset_name,  # Dataset name. string\n",
    "                        ood_dataset_names,  # OOD dataset names.  list of strings\n",
    "                        unscaled_ood,  # If true consider also unscaled versions of ood datasets. boolean\n",
    "                        split,  # Split for train/val/test sets. list of floats\n",
    "                        transform_min,  # Minimum value for rescaling input data. float\n",
    "                        transform_max,  # Maximum value for rescaling input data. float\n",
    "\n",
    "                        # Architecture parameters\n",
    "                        seed_model,  # Seed to init model. int\n",
    "                        directory_model,  # Path to save model. string\n",
    "                        architecture,  # Encoder architecture name. string\n",
    "                        input_dims,  # Input dimension. List of ints\n",
    "                        output_dim,  # Output dimension. int\n",
    "                        hidden_dims,  # Hidden dimensions. list of ints\n",
    "                        kernel_dim,  # Input dimension. int\n",
    "                        latent_dim,  # Latent dimension. int\n",
    "                        no_density,  # Use density estimation or not. boolean\n",
    "                        density_type,  # Density type. string\n",
    "                        n_density,  # Number of density components. int\n",
    "                        k_lipschitz,  # Lipschitz constant. float or None (if no lipschitz)\n",
    "                        budget_function,  # Budget function name applied on class count. name\n",
    "\n",
    "                        # Training parameters\n",
    "                        directory_results,  # Path to save resutls. string\n",
    "                        max_epochs,  # Maximum number of epochs for training\n",
    "                        patience,  # Patience for early stopping. int\n",
    "                        frequency,  # Frequency for early stopping test. int\n",
    "                        batch_size,  # Batch size. int\n",
    "                        lr,  # Learning rate. float\n",
    "                        loss,  # Loss name. string\n",
    "                        training_mode,  # 'joint' or 'sequential' training. string\n",
    "                        regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../saved_models/model-dpn-123-segment_scale_sky_missing-[0.6, 0.8]-0.0-1.0-123-linear-[18]-6-[64, 64, 64]-None-6-False-normal_mixture-6-None-id-200-10-2-64-0.001-UCE-joint-1e-05\n",
      "../saved_results/results-dpn-123-segment_scale_sky_missing-[0.6, 0.8]-0.0-1.0-123-linear-[18]-6-[64, 64, 64]-None-6-False-normal_mixture-6-None-id-200-10-2-64-0.001-UCE-joint-1e-05\n"
     ]
    }
   ],
   "source": [
    "print(results_metrics['model_path'])\n",
    "print(results_metrics['result_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9772727272727273\n",
      "confidence_aleatoric 0.9990720865506031\n",
      "confidence_epistemic 0.9987970080676583\n",
      "brier_score 0.07922945596619664\n",
      "anomaly_detection_aleatoric_segment_scale_sky_only 0.9543796504240085\n",
      "anomaly_detection_epistemic_segment_scale_sky_only 0.9631870408624367\n"
     ]
    }
   ],
   "source": [
    "no_show = ['model_path', 'result_path', 'train_losses', 'val_losses', 'test_losses', 'train_accuracies', 'val_accuracies', 'test_accuracies', 'fail_trace']\n",
    "for k, v in results_metrics.items():\n",
    "    if k not in no_show:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/saeedzou/PostNet.git\n",
    "!pip -q install pyro-ppl\n",
    "\n",
    "import os\n",
    "print(\"Current Working Directory \" , os.getcwd())\n",
    "import sys\n",
    "sys.path.append(\"PostNet\") # Add directory containing src/data to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "from src.posterior_networks.run import run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "seed_dataset=1\n",
    "directory_dataset='PostNet/data'\n",
    "dataset_name='2DGaussians-0.2'\n",
    "ood_dataset_names=['anomalous-2Ddataset']\n",
    "unscaled_ood=False\n",
    "split=[.6, .8]\n",
    "transform_min=0.\n",
    "transform_max=1.\n",
    "\n",
    "# Architecture parameters\n",
    "seed_model=123\n",
    "directory_model='PostNet/saved_models'\n",
    "architecture='linear'\n",
    "input_dims=[2]\n",
    "output_dim=3\n",
    "hidden_dims=[64, 64, 64]\n",
    "kernel_dim=None\n",
    "latent_dim=6\n",
    "no_density=False\n",
    "density_type='radial_flow'\n",
    "n_density=6\n",
    "k_lipschitz=None\n",
    "budget_function='id'\n",
    "\n",
    "# Training parameters\n",
    "directory_results='PostNet/saved_results'\n",
    "max_epochs=200\n",
    "patience=10\n",
    "frequency=2\n",
    "batch_size=64\n",
    "lr=1e-3\n",
    "loss='UCE'\n",
    "training_mode='joint'\n",
    "regr=1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/staff-hdd/charpent/anaconda3/envs/posterior-network/lib/python3.6/site-packages/torch/autograd/anomaly_mode.py:70: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  warnings.warn('Anomaly Detection has been enabled. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> Val loss 1.552 | Val Acc.: 0.343\n",
      "Model saved\n",
      "Epoch 2 -> Val loss 0.997 | Val Acc.: 0.597\n",
      "Model saved\n",
      "Epoch 4 -> Val loss 0.983 | Val Acc.: 0.793\n",
      "Model saved\n",
      "Epoch 6 -> Val loss 0.989 | Val Acc.: 0.793\n",
      "Epoch 8 -> Val loss 0.968 | Val Acc.: 0.85\n",
      "Model saved\n",
      "Epoch 10 -> Val loss 0.975 | Val Acc.: 0.897\n",
      "Epoch 12 -> Val loss 0.952 | Val Acc.: 0.903\n",
      "Model saved\n",
      "Epoch 14 -> Val loss 0.924 | Val Acc.: 0.96\n",
      "Model saved\n",
      "Epoch 16 -> Val loss 0.869 | Val Acc.: 0.98\n",
      "Model saved\n",
      "Epoch 18 -> Val loss 0.743 | Val Acc.: 0.99\n",
      "Model saved\n",
      "Epoch 20 -> Val loss 0.625 | Val Acc.: 0.997\n",
      "Model saved\n",
      "Epoch 22 -> Val loss 0.499 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 24 -> Val loss 0.325 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 26 -> Val loss 0.16 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 28 -> Val loss 0.063 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 30 -> Val loss 0.055 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 32 -> Val loss 0.052 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 34 -> Val loss 0.042 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 36 -> Val loss 0.023 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 38 -> Val loss 0.025 | Val Acc.: 1.0\n",
      "Epoch 40 -> Val loss 0.021 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 42 -> Val loss 0.017 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 44 -> Val loss 0.016 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 46 -> Val loss 0.012 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 48 -> Val loss 0.01 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 50 -> Val loss 0.021 | Val Acc.: 1.0\n",
      "Epoch 52 -> Val loss 0.011 | Val Acc.: 1.0\n",
      "Epoch 54 -> Val loss 0.009 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 56 -> Val loss 0.011 | Val Acc.: 1.0\n",
      "Epoch 58 -> Val loss 0.006 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 60 -> Val loss 0.009 | Val Acc.: 1.0\n",
      "Epoch 62 -> Val loss 0.007 | Val Acc.: 1.0\n",
      "Epoch 64 -> Val loss 0.005 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 66 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 68 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 70 -> Val loss 0.007 | Val Acc.: 1.0\n",
      "Epoch 72 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 74 -> Val loss 0.003 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 76 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Epoch 78 -> Val loss 0.005 | Val Acc.: 1.0\n",
      "Epoch 80 -> Val loss 0.003 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 82 -> Val loss 0.003 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 84 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Epoch 86 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 88 -> Val loss 0.003 | Val Acc.: 1.0\n",
      "Epoch 90 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 92 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 94 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Epoch 96 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Epoch 98 -> Val loss 0.003 | Val Acc.: 1.0\n",
      "Epoch 100 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Epoch 102 -> Val loss 0.003 | Val Acc.: 1.0\n",
      "Epoch 104 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 106 -> Val loss 0.004 | Val Acc.: 1.0\n",
      "Epoch 108 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 110 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 112 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 114 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 116 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 118 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 120 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 122 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 124 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 126 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 128 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 130 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 132 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 134 -> Val loss 0.002 | Val Acc.: 1.0\n",
      "Epoch 136 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 138 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 140 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 142 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 144 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 146 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 148 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 150 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 152 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 154 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 156 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 158 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 160 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 162 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Model saved\n",
      "Epoch 164 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 166 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 168 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 170 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 172 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 174 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 176 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 178 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Epoch 180 -> Val loss 0.001 | Val Acc.: 1.0\n",
      "Early Stopping.\n"
     ]
    }
   ],
   "source": [
    "results_metrics = run(# Dataset parameters\n",
    "                        seed_dataset,  # Seed to shuffle dataset. int\n",
    "                        directory_dataset,  # Path to dataset. string\n",
    "                        dataset_name,  # Dataset name. string\n",
    "                        ood_dataset_names,  # OOD dataset names.  list of strings\n",
    "                        unscaled_ood,  # If true consider also unscaled versions of ood datasets. boolean\n",
    "                        split,  # Split for train/val/test sets. list of floats\n",
    "                        transform_min,  # Minimum value for rescaling input data. float\n",
    "                        transform_max,  # Maximum value for rescaling input data. float\n",
    "\n",
    "                        # Architecture parameters\n",
    "                        seed_model,  # Seed to init model. int\n",
    "                        directory_model,  # Path to save model. string\n",
    "                        architecture,  # Encoder architecture name. string\n",
    "                        input_dims,  # Input dimension. List of ints\n",
    "                        output_dim,  # Output dimension. int\n",
    "                        hidden_dims,  # Hidden dimensions. list of ints\n",
    "                        kernel_dim,  # Input dimension. int\n",
    "                        latent_dim,  # Latent dimension. int\n",
    "                        no_density,  # Use density estimation or not. boolean\n",
    "                        density_type,  # Density type. string\n",
    "                        n_density,  # Number of density components. int\n",
    "                        k_lipschitz,  # Lipschitz constant. float or None (if no lipschitz)\n",
    "                        budget_function,  # Budget function name applied on class count. name\n",
    "\n",
    "                        # Training parameters\n",
    "                        directory_results,  # Path to save resutls. string\n",
    "                        max_epochs,  # Maximum number of epochs for training\n",
    "                        patience,  # Patience for early stopping. int\n",
    "                        frequency,  # Frequency for early stopping test. int\n",
    "                        batch_size,  # Batch size. int\n",
    "                        lr,  # Learning rate. float\n",
    "                        loss,  # Loss name. string\n",
    "                        training_mode,  # 'joint' or 'sequential' training. string\n",
    "                        regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../saved_models/model-dpn-1-2DGaussians-0.2-[0.6, 0.8]-0.0-1.0-123-linear-[2]-3-[64, 64, 64]-None-6-False-radial_flow-6-None-id-200-10-2-64-0.001-UCE-joint-1e-05\n",
      "../saved_results/results-dpn-1-2DGaussians-0.2-[0.6, 0.8]-0.0-1.0-123-linear-[2]-3-[64, 64, 64]-None-6-False-radial_flow-6-None-id-200-10-2-64-0.001-UCE-joint-1e-05\n"
     ]
    }
   ],
   "source": [
    "print(results_metrics['model_path'])\n",
    "print(results_metrics['result_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 1.0\n",
      "confidence_aleatoric 1.0\n",
      "confidence_epistemic 1.0\n",
      "brier_score 0.0005389536995364834\n",
      "anomaly_detection_aleatoric_anomalous-2Ddataset 1.0\n",
      "anomaly_detection_epistemic_anomalous-2Ddataset 1.0\n"
     ]
    }
   ],
   "source": [
    "no_show = ['model_path', 'result_path', 'train_losses', 'val_losses', 'test_losses', 'train_accuracies', 'val_accuracies', 'test_accuracies', 'fail_trace']\n",
    "for k, v in results_metrics.items():\n",
    "    if k not in no_show:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
